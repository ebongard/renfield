# Production Docker Compose with NVIDIA GPU Support
# Usage: docker compose -f docker-compose.prod.yml up -d
#
# Prerequisites:
#   1. NVIDIA GPU with drivers installed (nvidia-smi should work)
#   2. NVIDIA Container Toolkit installed:
#      curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
#      curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
#        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
#        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
#      sudo apt update && sudo apt install -y nvidia-container-toolkit
#      sudo nvidia-ctk runtime configure --runtime=docker
#      sudo systemctl restart docker
#
# For external Ollama (recommended for production), set in .env:
#   OLLAMA_URL=http://cuda.local:11434
#
# For local Ollama with GPU:
#   docker compose -f docker-compose.prod.yml --profile ollama-gpu up -d

services:
  # PostgreSQL Datenbank mit pgvector für RAG
  postgres:
    image: pgvector/pgvector:pg16
    container_name: renfield-postgres
    environment:
      POSTGRES_DB: renfield
      POSTGRES_USER: renfield
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - renfield-network
    restart: always
    # Not exposed externally in production
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U renfield -d renfield"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Redis für Message Queue und Caching
  redis:
    image: redis:7-alpine
    container_name: renfield-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - renfield-network
    restart: always
    # Not exposed externally in production
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  # Ollama with GPU (optional - use external instance for better resource management)
  ollama-gpu:
    image: ollama/ollama:0.15.1
    container_name: renfield-ollama
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - renfield-network
    restart: always
    profiles:
      - ollama-gpu
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Backend API with GPU Support (Whisper acceleration)
  backend:
    build:
      context: ./src/backend
      dockerfile: Dockerfile.gpu
    container_name: renfield-backend
    env_file:
      - .env
    environment:
      DATABASE_URL: postgresql://renfield:${POSTGRES_PASSWORD:-changeme}@postgres:5432/renfield
      REDIS_URL: redis://redis:6379
      OLLAMA_URL: ${OLLAMA_URL:-http://ollama:11434}
      NVIDIA_VISIBLE_DEVICES: all
    volumes:
      - ./src/backend:/app
      - ./tests:/tests
      - ./pytest.ini:/pytest.ini
      - whisper_models:/root/.cache/whisper
      - piper_models:/root/.local/share/piper
      - rag_uploads:/app/data/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - renfield-network
    restart: always
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Backend exposed via nginx only

  # Frontend Web-App (Production build with nginx)
  frontend:
    build:
      context: ./src/frontend
      dockerfile: Dockerfile
      target: production
      args:
        VITE_API_URL: ${EXTERNAL_URL:-}/api
        VITE_WS_URL: ${EXTERNAL_WS_URL:-}/ws
    container_name: renfield-frontend
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - renfield-network
    restart: always
    # Health check is built into the Dockerfile for production stage
    # Frontend exposed via nginx reverse proxy only

  # Nginx Reverse Proxy (Production)
  nginx:
    image: nginx:1.28-alpine
    container_name: renfield-nginx
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/ssl:/etc/nginx/ssl:ro  # Optional: SSL certificates
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
    networks:
      - renfield-network
    ports:
      - "80:80"
      - "443:443"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "test -f /var/run/nginx.pid && kill -0 $(cat /var/run/nginx.pid)"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

networks:
  renfield-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  ollama_data:
  whisper_models:
  piper_models:
  rag_uploads:
