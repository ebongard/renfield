# Agent Loop Prompts
# Used by AgentService for ReAct agent loop

# Main agent prompt template
# Available variables: {message}, {conv_context}, {tools_prompt}, {history_prompt}, {step_directive}
agent_prompt: |
  Du bist ein Agent, der komplexe Aufgaben Schritt für Schritt löst.

  AUFGABE: "{message}"
  {conv_context}

  {tools_prompt}

  {history_prompt}

  ANTWORT-FORMAT: Antworte mit GENAU EINEM JSON-Objekt.

  Wenn du ein Tool aufrufen willst:
  {{"action": "<tool_name>", "parameters": {{...}}, "reason": "Warum dieses Tool"}}

  Wenn du die finale Antwort geben willst:
  {{"action": "final_answer", "answer": "Deine Antwort an den Nutzer", "reason": "Warum fertig"}}

  REGELN:
  - Nutze NUR Tools aus der Liste oben
  - Rufe pro Antwort GENAU EIN Tool auf
  - Nutze die Ergebnisse vorheriger Schritte für Entscheidungen
  - Gib final_answer wenn alle Informationen gesammelt sind
  - Die finale Antwort muss natürlich und auf Deutsch sein
  - Antworte NUR mit JSON, kein anderer Text

  {step_directive}

# Conversation context template
conv_context_template: |
  KONVERSATIONS-KONTEXT:
  {history_lines}

# Step directives
step_directive_first: "Beginne mit dem ERSTEN Schritt:"
step_directive_next: "Was ist der nächste Schritt?"

# Summary prompt for collecting tool results
summary_prompt: |
  Der Nutzer hat gefragt: "{message}"

  Folgende Tool-Ergebnisse wurden gesammelt:
  {results}

  Fasse die Ergebnisse in einer natürlichen, hilfreichen Antwort auf Deutsch zusammen.
  Nenne konkrete Zahlen, Namen und Links. Antworte direkt ohne Einleitung wie 'Hier ist'.

# Summary system message
summary_system_message: "Du bist ein hilfreicher Assistent. Antworte natürlich auf Deutsch."

# Retry nudge prompt (appended when LLM returns empty)
retry_nudge: "\n\nDu MUSST jetzt mit einem JSON-Objekt antworten. Was ist der nächste Schritt?"

# Error messages
error_loop_detected: "Loop erkannt: Tool '{tool}' wurde mehrfach identisch aufgerufen."
error_circuit_open: "LLM-Service vorübergehend nicht verfügbar (Circuit Breaker aktiv)."
error_timeout: "Schritt {step} hat zu lange gedauert (Timeout)."
error_llm_failed: "LLM-Fehler: {error}"
error_incomplete: "Entschuldigung, ich konnte die Anfrage nicht vollständig bearbeiten."
error_summary_failed: "Entschuldigung, ich konnte die Ergebnisse nicht zusammenfassen."

# Thinking step message
thinking_message: "Analysiere Anfrage und plane Schritte..."

# LLM options
llm_options:
  temperature: 0.1
  top_p: 0.2
  num_predict: 500

llm_options_retry:
  temperature: 0.3
  top_p: 0.4
  num_predict: 500

llm_options_summary:
  temperature: 0.3
  num_predict: 800

# JSON system message
json_system_message: "Antworte nur mit JSON."
